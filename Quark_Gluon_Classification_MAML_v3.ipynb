{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNAN3r6BAPFii7FUYYAswkn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnavsinghal09/GSoC-QMAML/blob/main/Quark_Gluon_Classification_MAML_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSSNKRvxVGfC",
        "outputId": "3759413a-08fc-4b15-e44c-61c8f59719be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Imports\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import random"
      ],
      "metadata": {
        "id": "aXBBLNaDY9rw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Hyperparameters\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/quark-gluon-dataset\"\n",
        "FILES = [\n",
        "    \"quark-gluon_train-set_n793900.hdf5\",\n",
        "    \"quark-gluon_test-set_n139306.hdf5\",\n",
        "    \"quark-gluon_test-set_n10000.hdf5\"\n",
        "]\n",
        "FILE_PATHS = [f\"{DATA_DIR}/{fname}\" for fname in FILES]\n",
        "FILE_LABELS = [\"Train\", \"Test1\", \"Test2\"]\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 2e-4\n",
        "EPOCHS = 30\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "IMG_SHAPE = (3, 125, 125)\n",
        "N_WAY = 2\n",
        "K_SHOT = 64\n",
        "K_QUERY = 128\n",
        "META_BATCH_SIZE = 8\n",
        "INNER_STEPS = 5\n",
        "INNER_LR = 1e-2\n",
        "NUM_WORKERS = 4"
      ],
      "metadata": {
        "id": "2syvlwAYZRoz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Dataset and Task Sampler\n",
        "\n",
        "class JetImageDataset(Dataset):\n",
        "    def __init__(self, X, y, pt=None, pt_bins=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.pt = pt\n",
        "        self.pt_bins = pt_bins\n",
        "        if self.pt is not None and self.pt_bins is not None:\n",
        "            self.bin_indices = []\n",
        "            for i in range(len(pt_bins) - 1):\n",
        "                idx = np.where((pt >= pt_bins[i]) & (pt < pt_bins[i+1]))[0]\n",
        "                self.bin_indices.append(idx)\n",
        "        else:\n",
        "            self.bin_indices = [np.arange(len(y))]\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx]\n",
        "        if x.shape != IMG_SHAPE:\n",
        "            x = np.transpose(x, (2, 0, 1))  # (3, 125, 125)\n",
        "        label = int(self.y[idx])\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "def sample_task(dataset, bin_idx, k_shot, k_query):\n",
        "    idxs = dataset.bin_indices[bin_idx]\n",
        "    idxs = np.random.permutation(idxs)\n",
        "    support_idxs = idxs[:k_shot]\n",
        "    query_idxs = idxs[k_shot:k_shot + k_query]\n",
        "    X_s, y_s = zip(*[dataset[i] for i in support_idxs])\n",
        "    X_q, y_q = zip(*[dataset[i] for i in query_idxs])\n",
        "    return (torch.stack(X_s), torch.tensor(y_s)), (torch.stack(X_q), torch.tensor(y_q))"
      ],
      "metadata": {
        "id": "d-J4ymZFmeKd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. CNN Module\n",
        "\n",
        "class JetCNN(nn.Module):\n",
        "    def __init__(self, n_classes=2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 5, stride=2, padding=2), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 3, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 3, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 4 * 4, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 256), nn.ReLU(),\n",
        "            nn.Linear(256, n_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "WueLeVuHvvAX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Data Preparation and Meta-Task Definition\n",
        "\n",
        "with h5py.File(FILE_PATHS[0], \"r\") as f:\n",
        "    X = np.array(f[\"X_jets\"][:100000])  # Use more data for better GPU usage\n",
        "    y = np.array(f[\"y\"][:100000])\n",
        "    pt = np.array(f[\"pt\"][:100000])\n",
        "\n",
        "pt_bins = np.percentile(pt, np.linspace(0, 100, 6))\n",
        "print(\"pT bins:\", pt_bins)\n",
        "\n",
        "jet_dataset = JetImageDataset(X, y, pt=pt, pt_bins=pt_bins)\n",
        "\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "split = int(0.8 * len(indices))\n",
        "train_idx, val_idx = indices[:split], indices[split:]\n",
        "train_loader = DataLoader(\n",
        "    Subset(jet_dataset, train_idx),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    Subset(jet_dataset, val_idx),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    pin_memory=True,\n",
        "    num_workers=NUM_WORKERS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_sSr12cmiJK",
        "outputId": "636ef12a-dad1-40af-8e17-93ea313e6b39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pT bins: [ 70.23306274  95.22527161 105.78971405 117.68426208 135.88970642\n",
            " 323.42160034]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Training Loop for Classical Baseline (with All Stats)\n",
        "\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_pred = y_pred.cpu().numpy()\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    return acc, f1, prec, rec\n",
        "\n",
        "def train_baseline(model, train_loader, val_loader, epochs=EPOCHS):\n",
        "    model = model.to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        y_true_train, y_pred_train = [], []\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(X)\n",
        "            loss = loss_fn(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * X.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            y_true_train.append(y)\n",
        "            y_pred_train.append(preds)\n",
        "        y_true_train = torch.cat(y_true_train)\n",
        "        y_pred_train = torch.cat(y_pred_train)\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc, train_f1, train_prec, train_rec = compute_metrics(y_true_train, y_pred_train)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        y_true_val, y_pred_val = [], []\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "                logits = model(X)\n",
        "                loss = loss_fn(logits, y)\n",
        "                val_loss += loss.item() * X.size(0)\n",
        "                preds = logits.argmax(dim=1)\n",
        "                y_true_val.append(y)\n",
        "                y_pred_val.append(preds)\n",
        "        y_true_val = torch.cat(y_true_val)\n",
        "        y_pred_val = torch.cat(y_pred_val)\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc, val_f1, val_prec, val_rec = compute_metrics(y_true_val, y_pred_val)\n",
        "\n",
        "        print(f\"Epoch {epoch+1:2d} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f} | \"\n",
        "              f\"Prec: {train_prec:.4f} | Rec: {train_rec:.4f} || \"\n",
        "              f\"Val Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f} | \"\n",
        "              f\"Prec: {val_prec:.4f} | Rec: {val_rec:.4f}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "mOkm3tXwndH0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. MAML Meta-Learning Loop (with All Stats)\n",
        "\n",
        "def maml_train(model, dataset, pt_bins, meta_batch_size=META_BATCH_SIZE, epochs=EPOCHS):\n",
        "    model = model.to(DEVICE)\n",
        "    meta_optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    for epoch in range(epochs):\n",
        "        meta_loss = 0\n",
        "        all_y_true, all_y_pred = [], []\n",
        "        for _ in range(meta_batch_size):\n",
        "            bin_idx = random.randint(0, len(pt_bins)-2)\n",
        "            (X_s, y_s), (X_q, y_q) = sample_task(dataset, bin_idx, K_SHOT, K_QUERY)\n",
        "            X_s, y_s, X_q, y_q = X_s.to(DEVICE), y_s.to(DEVICE), X_q.to(DEVICE), y_q.to(DEVICE)\n",
        "            # Clone model for inner loop\n",
        "            fast_weights = [p.clone().detach().requires_grad_(True) for p in model.parameters()]\n",
        "            # Inner loop\n",
        "            for _ in range(INNER_STEPS):\n",
        "                logits = model(X_s)\n",
        "                loss = loss_fn(logits, y_s)\n",
        "                grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
        "                fast_weights = [w - INNER_LR * g for w, g in zip(fast_weights, grads)]\n",
        "            # Outer loop: evaluate on query set\n",
        "            def forward_with_weights(x, weights):\n",
        "              # Conv1\n",
        "              x = nn.functional.conv2d(x, weights[0], weights[1], stride=2, padding=2)\n",
        "              x = nn.functional.relu(x)\n",
        "              # Conv2\n",
        "              x = nn.functional.conv2d(x, weights[2], weights[3], stride=2, padding=1)\n",
        "              x = nn.functional.relu(x)\n",
        "              # Conv3\n",
        "              x = nn.functional.conv2d(x, weights[4], weights[5], stride=2, padding=1)\n",
        "              x = nn.functional.relu(x)\n",
        "              # Conv4\n",
        "              x = nn.functional.conv2d(x, weights[6], weights[7], stride=2, padding=1)\n",
        "              x = nn.functional.relu(x)\n",
        "              # Conv5\n",
        "              x = nn.functional.conv2d(x, weights[8], weights[9], stride=2, padding=1)\n",
        "              x = nn.functional.relu(x)\n",
        "              # Flatten\n",
        "              x = x.view(x.size(0), -1)\n",
        "              # FC1\n",
        "              x = nn.functional.linear(x, weights[10], weights[11])\n",
        "              x = nn.functional.relu(x)\n",
        "              # FC2\n",
        "              x = nn.functional.linear(x, weights[12], weights[13])\n",
        "              x = nn.functional.relu(x)\n",
        "              # FC3\n",
        "              x = nn.functional.linear(x, weights[14], weights[15])\n",
        "              return x\n",
        "            logits_q = forward_with_weights(X_q, fast_weights)\n",
        "            loss_q = loss_fn(logits_q, y_q)\n",
        "            meta_loss += loss_q\n",
        "            preds = logits_q.argmax(dim=1)\n",
        "            all_y_true.append(y_q)\n",
        "            all_y_pred.append(preds)\n",
        "        meta_optimizer.zero_grad()\n",
        "        meta_loss.backward()\n",
        "        meta_optimizer.step()\n",
        "        all_y_true = torch.cat(all_y_true)\n",
        "        all_y_pred = torch.cat(all_y_pred)\n",
        "        acc, f1, prec, rec = compute_metrics(all_y_true, all_y_pred)\n",
        "        print(f\"Epoch {epoch+1:2d} | Meta Loss: {meta_loss.item()/meta_batch_size:.4f} | \"\n",
        "              f\"Acc: {acc:.4f} | F1: {f1:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "A5-an-WPne8h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Train and Evaluate Baseline\n",
        "\n",
        "baseline_model = JetCNN()\n",
        "baseline_model = train_baseline(baseline_model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igD1nB40ng6C",
        "outputId": "7807c38e-084f-44fb-aef5-ac6d0410d2ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 | Train Loss: 0.6932 | Acc: 0.4986 | F1: 0.4677 | Prec: 0.4988 | Rec: 0.4402 || Val Loss: 0.6931 | Acc: 0.5034 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  2 | Train Loss: 0.6932 | Acc: 0.4990 | F1: 0.4445 | Prec: 0.4992 | Rec: 0.4006 || Val Loss: 0.6931 | Acc: 0.5034 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  3 | Train Loss: 0.6932 | Acc: 0.4993 | F1: 0.5368 | Prec: 0.4997 | Rec: 0.5799 || Val Loss: 0.6931 | Acc: 0.5034 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  4 | Train Loss: 0.6931 | Acc: 0.5008 | F1: 0.4562 | Prec: 0.5014 | Rec: 0.4184 || Val Loss: 0.6933 | Acc: 0.4965 | F1: 0.6635 | Prec: 0.4965 | Rec: 0.9996\n",
            "Epoch  5 | Train Loss: 0.6931 | Acc: 0.4999 | F1: 0.5991 | Prec: 0.5002 | Rec: 0.7468 || Val Loss: 0.6937 | Acc: 0.5034 | F1: 0.0006 | Prec: 0.5000 | Rec: 0.0003\n",
            "Epoch  6 | Train Loss: 0.6931 | Acc: 0.4996 | F1: 0.3457 | Prec: 0.5000 | Rec: 0.2641 || Val Loss: 0.6935 | Acc: 0.4964 | F1: 0.6634 | Prec: 0.4965 | Rec: 0.9995\n",
            "Epoch  7 | Train Loss: 0.6777 | Acc: 0.5566 | F1: 0.5879 | Prec: 0.5495 | Rec: 0.6321 || Val Loss: 0.6000 | Acc: 0.6896 | F1: 0.6899 | Prec: 0.6845 | Rec: 0.6954\n",
            "Epoch  8 | Train Loss: 0.5947 | Acc: 0.6906 | F1: 0.6974 | Prec: 0.6829 | Rec: 0.7126 || Val Loss: 0.5873 | Acc: 0.6991 | F1: 0.7068 | Prec: 0.6847 | Rec: 0.7305\n",
            "Epoch  9 | Train Loss: 0.5878 | Acc: 0.6956 | F1: 0.7043 | Prec: 0.6854 | Rec: 0.7243 || Val Loss: 0.5865 | Acc: 0.6995 | F1: 0.7132 | Prec: 0.6779 | Rec: 0.7524\n",
            "Epoch 10 | Train Loss: 0.5846 | Acc: 0.6974 | F1: 0.7048 | Prec: 0.6885 | Rec: 0.7219 || Val Loss: 0.5856 | Acc: 0.7007 | F1: 0.7122 | Prec: 0.6815 | Rec: 0.7459\n",
            "Epoch 11 | Train Loss: 0.5814 | Acc: 0.7016 | F1: 0.7080 | Prec: 0.6937 | Rec: 0.7229 || Val Loss: 0.5845 | Acc: 0.7037 | F1: 0.7111 | Prec: 0.6893 | Rec: 0.7343\n",
            "Epoch 12 | Train Loss: 0.5767 | Acc: 0.7043 | F1: 0.7093 | Prec: 0.6980 | Rec: 0.7210 || Val Loss: 0.5842 | Acc: 0.7075 | F1: 0.7077 | Prec: 0.7025 | Rec: 0.7129\n",
            "Epoch 13 | Train Loss: 0.5705 | Acc: 0.7108 | F1: 0.7150 | Prec: 0.7052 | Rec: 0.7250 || Val Loss: 0.5703 | Acc: 0.7190 | F1: 0.7117 | Prec: 0.7255 | Rec: 0.6983\n",
            "Epoch 14 | Train Loss: 0.5614 | Acc: 0.7178 | F1: 0.7199 | Prec: 0.7151 | Rec: 0.7248 || Val Loss: 0.5728 | Acc: 0.7190 | F1: 0.7266 | Prec: 0.7030 | Rec: 0.7518\n",
            "Epoch 15 | Train Loss: 0.5562 | Acc: 0.7234 | F1: 0.7229 | Prec: 0.7247 | Rec: 0.7211 || Val Loss: 0.5829 | Acc: 0.7195 | F1: 0.7039 | Prec: 0.7397 | Rec: 0.6714\n",
            "Epoch 16 | Train Loss: 0.5524 | Acc: 0.7267 | F1: 0.7259 | Prec: 0.7286 | Rec: 0.7233 || Val Loss: 0.5807 | Acc: 0.7241 | F1: 0.7168 | Prec: 0.7312 | Rec: 0.7029\n",
            "Epoch 17 | Train Loss: 0.5514 | Acc: 0.7272 | F1: 0.7257 | Prec: 0.7304 | Rec: 0.7212 || Val Loss: 0.5848 | Acc: 0.7236 | F1: 0.7058 | Prec: 0.7486 | Rec: 0.6676\n",
            "Epoch 18 | Train Loss: 0.5484 | Acc: 0.7293 | F1: 0.7270 | Prec: 0.7337 | Rec: 0.7204 || Val Loss: 0.6105 | Acc: 0.7244 | F1: 0.7279 | Prec: 0.7139 | Rec: 0.7425\n",
            "Epoch 19 | Train Loss: 0.5476 | Acc: 0.7297 | F1: 0.7269 | Prec: 0.7351 | Rec: 0.7188 || Val Loss: 0.5924 | Acc: 0.7242 | F1: 0.7198 | Prec: 0.7263 | Rec: 0.7135\n",
            "Epoch 20 | Train Loss: 0.5434 | Acc: 0.7327 | F1: 0.7294 | Prec: 0.7389 | Rec: 0.7202 || Val Loss: 0.5939 | Acc: 0.7245 | F1: 0.7264 | Prec: 0.7167 | Rec: 0.7363\n",
            "Epoch 21 | Train Loss: 0.5405 | Acc: 0.7339 | F1: 0.7304 | Prec: 0.7407 | Rec: 0.7205 || Val Loss: 0.6411 | Acc: 0.7106 | F1: 0.6763 | Prec: 0.7606 | Rec: 0.6088\n",
            "Epoch 22 | Train Loss: 0.5387 | Acc: 0.7359 | F1: 0.7323 | Prec: 0.7431 | Rec: 0.7217 || Val Loss: 0.6153 | Acc: 0.7236 | F1: 0.7197 | Prec: 0.7248 | Rec: 0.7148\n",
            "Epoch 23 | Train Loss: 0.5357 | Acc: 0.7389 | F1: 0.7347 | Prec: 0.7473 | Rec: 0.7226 || Val Loss: 0.6219 | Acc: 0.7165 | F1: 0.6995 | Prec: 0.7383 | Rec: 0.6646\n",
            "Epoch 24 | Train Loss: 0.5310 | Acc: 0.7408 | F1: 0.7362 | Prec: 0.7503 | Rec: 0.7226 || Val Loss: 0.6260 | Acc: 0.7214 | F1: 0.7129 | Prec: 0.7300 | Rec: 0.6966\n",
            "Epoch 25 | Train Loss: 0.5277 | Acc: 0.7425 | F1: 0.7370 | Prec: 0.7538 | Rec: 0.7209 || Val Loss: 0.6453 | Acc: 0.7232 | F1: 0.7290 | Prec: 0.7096 | Rec: 0.7495\n",
            "Epoch 26 | Train Loss: 0.5232 | Acc: 0.7463 | F1: 0.7409 | Prec: 0.7575 | Rec: 0.7251 || Val Loss: 0.6248 | Acc: 0.7199 | F1: 0.7204 | Prec: 0.7142 | Rec: 0.7267\n",
            "Epoch 27 | Train Loss: 0.5208 | Acc: 0.7479 | F1: 0.7415 | Prec: 0.7612 | Rec: 0.7229 || Val Loss: 0.6254 | Acc: 0.7178 | F1: 0.7132 | Prec: 0.7201 | Rec: 0.7065\n",
            "Epoch 28 | Train Loss: 0.5151 | Acc: 0.7509 | F1: 0.7445 | Prec: 0.7648 | Rec: 0.7252 || Val Loss: 0.6553 | Acc: 0.7160 | F1: 0.7242 | Prec: 0.6995 | Rec: 0.7507\n",
            "Epoch 29 | Train Loss: 0.5093 | Acc: 0.7550 | F1: 0.7483 | Prec: 0.7699 | Rec: 0.7278 || Val Loss: 0.6951 | Acc: 0.7088 | F1: 0.6850 | Prec: 0.7402 | Rec: 0.6374\n",
            "Epoch 30 | Train Loss: 0.5033 | Acc: 0.7585 | F1: 0.7517 | Prec: 0.7742 | Rec: 0.7304 || Val Loss: 0.7240 | Acc: 0.7180 | F1: 0.7090 | Prec: 0.7270 | Rec: 0.6919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Train and Evaluate MAML\n",
        "\n",
        "maml_model = JetCNN()\n",
        "maml_model = maml_train(maml_model, jet_dataset, pt_bins)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPSsrcFjnisV",
        "outputId": "57c517d8-1780-42ea-9129-5a13e3996861"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 | Meta Loss: 0.6951 | Acc: 0.4639 | F1: 0.6338 | Prec: 0.4639 | Rec: 1.0000\n",
            "Epoch  2 | Meta Loss: 0.6909 | Acc: 0.5371 | F1: 0.6989 | Prec: 0.5371 | Rec: 1.0000\n",
            "Epoch  3 | Meta Loss: 0.6909 | Acc: 0.5332 | F1: 0.6955 | Prec: 0.5332 | Rec: 1.0000\n",
            "Epoch  4 | Meta Loss: 0.6932 | Acc: 0.5059 | F1: 0.6719 | Prec: 0.5059 | Rec: 1.0000\n",
            "Epoch  5 | Meta Loss: 0.6969 | Acc: 0.4727 | F1: 0.6419 | Prec: 0.4727 | Rec: 1.0000\n",
            "Epoch  6 | Meta Loss: 0.6967 | Acc: 0.4834 | F1: 0.6517 | Prec: 0.4834 | Rec: 1.0000\n",
            "Epoch  7 | Meta Loss: 0.6892 | Acc: 0.5430 | F1: 0.7038 | Prec: 0.5430 | Rec: 1.0000\n",
            "Epoch  8 | Meta Loss: 0.7045 | Acc: 0.4727 | F1: 0.6419 | Prec: 0.4727 | Rec: 1.0000\n",
            "Epoch  9 | Meta Loss: 0.7171 | Acc: 0.4453 | F1: 0.6162 | Prec: 0.4453 | Rec: 1.0000\n",
            "Epoch 10 | Meta Loss: 0.7156 | Acc: 0.4922 | F1: 0.6597 | Prec: 0.4922 | Rec: 1.0000\n",
            "Epoch 11 | Meta Loss: 0.7313 | Acc: 0.5039 | F1: 0.6701 | Prec: 0.5039 | Rec: 1.0000\n",
            "Epoch 12 | Meta Loss: 0.7595 | Acc: 0.4795 | F1: 0.6482 | Prec: 0.4795 | Rec: 1.0000\n",
            "Epoch 13 | Meta Loss: 0.7420 | Acc: 0.4873 | F1: 0.6553 | Prec: 0.4873 | Rec: 1.0000\n",
            "Epoch 14 | Meta Loss: 0.7043 | Acc: 0.4805 | F1: 0.6491 | Prec: 0.4805 | Rec: 1.0000\n",
            "Epoch 15 | Meta Loss: 0.6947 | Acc: 0.4814 | F1: 0.3253 | Prec: 0.5000 | Rec: 0.2411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 | Meta Loss: 0.6951 | Acc: 0.5166 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 | Meta Loss: 0.6889 | Acc: 0.5527 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 | Meta Loss: 0.7111 | Acc: 0.4893 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 | Meta Loss: 0.7042 | Acc: 0.5068 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 | Meta Loss: 0.7007 | Acc: 0.5049 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 | Meta Loss: 0.7063 | Acc: 0.4600 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 | Meta Loss: 0.6932 | Acc: 0.5254 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 | Meta Loss: 0.6949 | Acc: 0.4951 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 | Meta Loss: 0.6930 | Acc: 0.5088 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 | Meta Loss: 0.6924 | Acc: 0.5107 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 | Meta Loss: 0.6932 | Acc: 0.4883 | F1: 0.0000 | Prec: 0.0000 | Rec: 0.0000\n",
            "Epoch 27 | Meta Loss: 0.6927 | Acc: 0.5234 | F1: 0.2254 | Prec: 0.5547 | Rec: 0.1414\n",
            "Epoch 28 | Meta Loss: 0.6929 | Acc: 0.5381 | F1: 0.4679 | Prec: 0.5417 | Rec: 0.4119\n",
            "Epoch 29 | Meta Loss: 0.6925 | Acc: 0.5225 | F1: 0.3311 | Prec: 0.4727 | Rec: 0.2547\n",
            "Epoch 30 | Meta Loss: 0.6929 | Acc: 0.5312 | F1: 0.5229 | Prec: 0.5137 | Rec: 0.5324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Few-Shot Evaluation Function\n",
        "\n",
        "def few_shot_eval(model, dataset, pt_bins, n_tasks=None, k_shot=K_SHOT, k_query=K_QUERY, inner_steps=INNER_STEPS, inner_lr=INNER_LR):\n",
        "    model.eval()\n",
        "    all_acc, all_f1, all_prec, all_rec = [], [], [], []\n",
        "    n_bins = len(pt_bins) - 1 if n_tasks is None else n_tasks\n",
        "    for bin_idx in range(n_bins):\n",
        "        (X_s, y_s), (X_q, y_q) = sample_task(dataset, bin_idx, k_shot, k_query)\n",
        "        X_s, y_s, X_q, y_q = X_s.to(DEVICE), y_s.to(DEVICE), X_q.to(DEVICE), y_q.to(DEVICE)\n",
        "        # Fast adaptation (inner loop)\n",
        "        fast_weights = [p.clone().detach().requires_grad_(True) for p in model.parameters()]\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        for _ in range(inner_steps):\n",
        "            logits = model(X_s)\n",
        "            loss = loss_fn(logits, y_s)\n",
        "            grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
        "            fast_weights = [w - inner_lr * g for w, g in zip(fast_weights, grads)]\n",
        "        # Evaluate on query set\n",
        "        def forward_with_weights(x, weights):\n",
        "          # Conv1\n",
        "          x = nn.functional.conv2d(x, weights[0], weights[1], stride=2, padding=2)\n",
        "          x = nn.functional.relu(x)\n",
        "          # Conv2\n",
        "          x = nn.functional.conv2d(x, weights[2], weights[3], stride=2, padding=1)\n",
        "          x = nn.functional.relu(x)\n",
        "          # Conv3\n",
        "          x = nn.functional.conv2d(x, weights[4], weights[5], stride=2, padding=1)\n",
        "          x = nn.functional.relu(x)\n",
        "          # Conv4\n",
        "          x = nn.functional.conv2d(x, weights[6], weights[7], stride=2, padding=1)\n",
        "          x = nn.functional.relu(x)\n",
        "          # Conv5\n",
        "          x = nn.functional.conv2d(x, weights[8], weights[9], stride=2, padding=1)\n",
        "          x = nn.functional.relu(x)\n",
        "          # Flatten\n",
        "          x = x.view(x.size(0), -1)\n",
        "          # FC1\n",
        "          x = nn.functional.linear(x, weights[10], weights[11])\n",
        "          x = nn.functional.relu(x)\n",
        "          # FC2\n",
        "          x = nn.functional.linear(x, weights[12], weights[13])\n",
        "          x = nn.functional.relu(x)\n",
        "          # FC3\n",
        "          x = nn.functional.linear(x, weights[14], weights[15])\n",
        "          return x\n",
        "        logits_q = forward_with_weights(X_q, fast_weights)\n",
        "        preds = logits_q.argmax(dim=1)\n",
        "        acc = accuracy_score(y_q.cpu().numpy(), preds.cpu().numpy())\n",
        "        f1 = f1_score(y_q.cpu().numpy(), preds.cpu().numpy())\n",
        "        prec = precision_score(y_q.cpu().numpy(), preds.cpu().numpy())\n",
        "        rec = recall_score(y_q.cpu().numpy(), preds.cpu().numpy())\n",
        "        all_acc.append(acc)\n",
        "        all_f1.append(f1)\n",
        "        all_prec.append(prec)\n",
        "        all_rec.append(rec)\n",
        "        print(f\"Bin {bin_idx}: Acc={acc:.4f} | F1={f1:.4f} | Prec={prec:.4f} | Rec={rec:.4f}\")\n",
        "    print(f\"\\nMean Few-Shot: Acc={np.mean(all_acc):.4f} | F1={np.mean(all_f1):.4f} | Prec={np.mean(all_prec):.4f} | Rec={np.mean(all_rec):.4f}\")\n",
        "    return all_acc, all_f1, all_prec, all_rec"
      ],
      "metadata": {
        "id": "UDHNCW8Fw5hX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Few-Shot Evaluation for MAML and Baseline\n",
        "\n",
        "print(\"MAML Few-Shot Evaluation:\")\n",
        "few_shot_eval(maml_model, jet_dataset, pt_bins)\n",
        "\n",
        "print(\"\\nClassical Baseline Few-Shot Evaluation (no adaptation):\")\n",
        "# For baseline, skip adaptation: just forward pass\n",
        "def baseline_few_shot_eval(model, dataset, pt_bins, n_tasks=None, k_query=K_QUERY):\n",
        "    model.eval()\n",
        "    all_acc, all_f1, all_prec, all_rec = [], [], [], []\n",
        "    n_bins = len(pt_bins) - 1 if n_tasks is None else n_tasks\n",
        "    for bin_idx in range(n_bins):\n",
        "        idxs = dataset.bin_indices[bin_idx]\n",
        "        idxs = np.random.permutation(idxs)\n",
        "        query_idxs = idxs[:k_query]\n",
        "        X_q, y_q = zip(*[dataset[i] for i in query_idxs])\n",
        "        X_q = torch.stack(X_q).to(DEVICE)\n",
        "        y_q = torch.tensor(y_q).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            logits_q = model(X_q)\n",
        "            preds = logits_q.argmax(dim=1)\n",
        "        acc = accuracy_score(y_q.cpu().numpy(), preds.cpu().numpy())\n",
        "        f1 = f1_score(y_q.cpu().numpy(), preds.cpu().numpy())\n",
        "        prec = precision_score(y_q.cpu().numpy(), preds.cpu().numpy())\n",
        "        rec = recall_score(y_q.cpu().numpy(), preds.cpu().numpy())\n",
        "        all_acc.append(acc)\n",
        "        all_f1.append(f1)\n",
        "        all_prec.append(prec)\n",
        "        all_rec.append(rec)\n",
        "        print(f\"Bin {bin_idx}: Acc={acc:.4f} | F1={f1:.4f} | Prec={prec:.4f} | Rec={rec:.4f}\")\n",
        "    print(f\"\\nMean Few-Shot: Acc={np.mean(all_acc):.4f} | F1={np.mean(all_f1):.4f} | Prec={np.mean(all_prec):.4f} | Rec={np.mean(all_rec):.4f}\")\n",
        "    return all_acc, all_f1, all_prec, all_rec\n",
        "\n",
        "baseline_few_shot_eval(baseline_model, jet_dataset, pt_bins)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnjrKesBw7H_",
        "outputId": "2c63a39e-7c09-49e1-8334-6ccef65cc5c3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAML Few-Shot Evaluation:\n",
            "Bin 0: Acc=0.5625 | F1=0.0000 | Prec=0.0000 | Rec=0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin 1: Acc=0.4688 | F1=0.0000 | Prec=0.0000 | Rec=0.0000\n",
            "Bin 2: Acc=0.4531 | F1=0.0000 | Prec=0.0000 | Rec=0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin 3: Acc=0.5391 | F1=0.7005 | Prec=0.5391 | Rec=1.0000\n",
            "Bin 4: Acc=0.5312 | F1=0.0000 | Prec=0.0000 | Rec=0.0000\n",
            "\n",
            "Mean Few-Shot: Acc=0.5109 | F1=0.1401 | Prec=0.1078 | Rec=0.2000\n",
            "\n",
            "Classical Baseline Few-Shot Evaluation (no adaptation):\n",
            "Bin 0: Acc=0.7656 | F1=0.7222 | Prec=0.8125 | Rec=0.6500\n",
            "Bin 1: Acc=0.6875 | F1=0.6774 | Prec=0.7119 | Rec=0.6462\n",
            "Bin 2: Acc=0.7891 | F1=0.7970 | Prec=0.8281 | Rec=0.7681\n",
            "Bin 3: Acc=0.7891 | F1=0.7874 | Prec=0.7937 | Rec=0.7812\n",
            "Bin 4: Acc=0.8125 | F1=0.8310 | Prec=0.8551 | Rec=0.8082\n",
            "\n",
            "Mean Few-Shot: Acc=0.7688 | F1=0.7630 | Prec=0.8002 | Rec=0.7307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.765625, 0.6875, 0.7890625, 0.7890625, 0.8125],\n",
              " [0.7222222222222222,\n",
              "  0.6774193548387096,\n",
              "  0.7969924812030075,\n",
              "  0.7874015748031497,\n",
              "  0.8309859154929577],\n",
              " [0.8125, 0.711864406779661, 0.828125, 0.7936507936507936, 0.855072463768116],\n",
              " [0.65, 0.6461538461538462, 0.7681159420289855, 0.78125, 0.8082191780821918])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}